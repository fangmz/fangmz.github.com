<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 论文笔记 | Fang's Blog]]></title>
  <link href="http://fangmz.github.io/blog/categories/lun-wen-bi-ji/atom.xml" rel="self"/>
  <link href="http://fangmz.github.io/"/>
  <updated>2013-08-17T19:44:14+08:00</updated>
  <id>http://fangmz.github.io/</id>
  <author>
    <name><![CDATA[Fangmz]]></name>
    <email><![CDATA[fangmingzhe@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[论文笔记：2010From Tweets...]]></title>
    <link href="http://fangmz.github.io/blog/2013/08/17/lun-wen-bi-ji-%3A2010from-tweets-dot-dot-dot/"/>
    <updated>2013-08-17T18:46:00+08:00</updated>
    <id>http://fangmz.github.io/blog/2013/08/17/lun-wen-bi-ji-:2010from-tweets-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>主要内容：从社交网络中抽取民意，这对于自然语言计算是一个挑战，激发了计算语言学的研究。本文将选票中测量出的民意与来自微博(twitter等）上的文本分析出的情感联系起来。从时间上串起来与选票比较。时间平滑处理对与模型成败来说是个重要问题。结论是文本分析出的结果与选票数据是相关的。</p>

<p><strong>数据：</strong></p>

<ol>
<li>Twitter</li>
<li>公众民意测验（传统标准民意调查技术）</li>
</ol>


<p><strong>文本分析：</strong><br/>
两个子问题：</p>

<ol>
<li>消息提取：是否与主题相关</li>
<li>意见评估：积极或者消极，或者是关于话题的新闻</li>
</ol>


<p>如果训练数据充足可以用Mei et al 2007的话题——情感模型。这里情况是异步的，每天产生大量文本消息，但是选票数据很小。挑战：难以评估模型。信噪比问题：只对文本消息中的一小部分感兴趣。在话题关键字的上下文中对积极词汇和消极词汇进行计数。</p>

<p><strong>消息检索：</strong><br/>
关键字：</p>

<ol>
<li>消费者信心：economy job jobs.</li>
<li>总统满意度：obama</li>
<li>选举： obama mccain</li>
</ol>


<p><strong>意见评估:</strong><br/>
使用已有研究成果：积极消极词汇表。定义情感评分为同时包含话题词汇与积极词汇的数量比上同时包含话题词汇与消极词汇的数量。</p>
]]></content>
  </entry>
  
</feed>
